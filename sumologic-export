#!/usr/bin/env python3
"""
sumologic-export
~~~~~~~~~~~~~~~~

Export your Sumologic logs easily and quickly.

Usage:
    sumologic-export configure
    sumologic-export
    sumologic-export <start> <stop>
    sumologic-export
        (<start> | -s <start> | --start <start>)
        [(<stop> | -t <stop> | --stop <stop>)]
    sumologic-export (-h | --help)
    sumologic-export (-v | --version)

Written by Randall Degges (http://www.rdegges.com)
Updated by Caleb Fogleman
"""

from __future__ import print_function

from datetime import datetime, timedelta
from json import dumps, loads
from os import chmod, mkdir
from os.path import exists, expanduser
from subprocess import call
from time import sleep

from docopt import docopt
from requests import get, post


##### GLOBALS
VERSION = '0.0.3'
CONFIG_FILE = expanduser('~/.sumo')


# Pretty print datetime objects.
prettify = lambda x: x.strftime('%Y-%m-%dT%H:%M:%S')


class Exporter(object):
    """Abstraction for exporting Sumologic logs."""

    # Partition name to query (or *)
    PARTITION = '*'

    # Default time increment to move forward by.
    INCREMENT = timedelta(minutes=30)

    # Default timerange to use if no dates are specified.
    DEFAULT_TIMERANGE = timedelta(days=30)

    # Sumologic API constants.
    SUMOLOGIC_URL = 'https://api.us2.sumologic.com/api/v1/search/jobs'
    SUMOLOGIC_HEADERS = {
        'content-type': 'application/json',
        'accept': 'application/json',
    }

    # Amount of time to wait for API response.
    TIMEOUT = 30

    # Sumologic timezone to specify.
    TIMEZONE = 'EST'

    # Amount of time to pause before requesting Sumologic logs.  60 seconds
    # seems to be a good amount of time.
    SLEEP_SECONDS = 10

    # The amount of logs to download from Sumologic per page.  The higher this
    # is, the more memory is used, but the faster the exports are.
    MESSAGES_PER_PAGE = 10000

    def __init__(self):
        """
        Initialize this exporter.

        This includes:

        - Loading credentials.
        - Prepping the environment.
        - Setting up class variables.
        """
        if not exists(CONFIG_FILE):
            print('No credentials found! Run sumologic-export configure')
            raise SystemExit()

        if not exists('exports'):
            mkdir('exports')

        with open(CONFIG_FILE, 'rb') as cfg:
            creds = loads(cfg.read())
            self.credentials = (creds['access_id'], creds['access_key'])

        self.cookies = None

    def init_dates(self, start, stop):
        """
        Validate and initialize the date inputs we get from the user.

        We'll:

        - Ensure the dates are valid.
        - Perform cleanup.
        - If no dates are specified, we'll set defaults.
        """
        if start:
            try:
                self.start = datetime.strptime(start, '%Y-%m-%d').replace(hour=0, minute=0, second=0, microsecond=0)
            except:
                print('Invalid date format. Format must be YYYY-MM-DD.')
                raise SystemExit(1)

            if self.start > datetime.now():
                print('Start date must be in the past!')
                raise SystemExit(1)
        else:
            self.start = (datetime.now() - self.DEFAULT_TIMERANGE).replace(hour=0, minute=0, second=0, microsecond=0)

        if stop:
            try:
                self.stop = datetime.strptime(stop, '%Y-%m-%d').replace(hour=0, minute=0, second=0, microsecond=0)
            except:
                print('Invalid date format. Format must be YYYY-MM-DD.')
                raise SystemExit(1)

            if self.stop > datetime.now():
                print('Stop date must be in the past!')
                raise SystemExit(1)
        else:
            self.stop = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

    def export(self, start, stop):
        """
        Export all Sumologic logs from start to stop.

        All logs will be downloaded one day at a time, and put into a local
        folder named 'exports'.

        :param str start: The datetime at which to start downloading logs.
        :param str stop: The datetime at which to stop downloading logs.
        """
        # Validate / cleanup the date inputs.
        self.init_dates(start, stop)

        print(f'Exporting all logs from: {prettify(self.start)} to {prettify(self.stop)}... This may take a while.\n')

        print('Exporting Logs')
        print('--------------')

        date = self.start
        while date < self.stop:

            # Schedule the Sumologic job.
            job_url = self.create_job(date, date + self.INCREMENT)
            print('-', prettify(date))

            # Pause to allow Sumologic to process this job.
            sleep(self.SLEEP_SECONDS)

            # Figure out how many logs there are for the given date.
            total_logs = self.get_count(job_url)

            # If there are logs to be downloaded, let's do it.
            if total_logs:
                print(f' - Downloading {total_logs} logs.')

                logs = []
                for log in self.get_logs(job_url, total_logs):
                    logs.append(log)

                print(f' - Writing log file: exports/{prettify(date)}.json')
                with open(f'exports/{prettify(date)}.json', 'w') as exports:
                    exports.write(dumps(logs, indent=2, sort_keys=True))

                print(f' - Compressing log file: exports/{prettify(date)}.json')
                call(['gzip', '-9', f'exports/{prettify(date)}.json'])
            else:
                print(' - No logs found.')

            # Move forward.
            date += self.INCREMENT

        print('\nFinished downloading logs!')

    def create_job(self, start, stop):
        """
        Request all Sumologic logs for the specified date range.

        :param datetime start: The date to start.
        :param datetime stop: The date to stop.

        :rtype: string
        :returns: The URL of the job.
        """
        while True:
            try:
                resp = post(
                    self.SUMOLOGIC_URL,
                    auth = self.credentials,
                    headers = self.SUMOLOGIC_HEADERS,
                    timeout = self.TIMEOUT,
                    data = dumps({
                        # 'query': '*',
                        'query': '_index=' + self.PARTITION + ' | fields _messagetime, _sourceName, _sourceCategory, _sourceHost, _raw',
                        'from': start.isoformat(),
                        'to': stop.isoformat(),
                        'timeZone': self.TIMEZONE,
                    }),
                    cookies = self.cookies,
                )
                if resp.cookies:
                    self.cookies = resp.cookies

                if resp.status_code == 202:
                    print('%s/%s' % (self.SUMOLOGIC_URL, resp.json()['id']))
                    return '%s/%s' % (self.SUMOLOGIC_URL, resp.json()['id'])

                raise
            except:
                sleep(1)

    def get_count(self, job_url):
        """
        Given a Sumologic job URL, figure out how many logs exist.

        :param str job_url: The job URL.

        :rtype: int
        :returns: The amount of logs found in the specified job results.
        """
        while True:
            try:
                resp = get(
                    job_url,
                    auth = self.credentials,
                    headers = self.SUMOLOGIC_HEADERS,
                    timeout = self.TIMEOUT,
                    cookies = self.cookies
                )
                if resp.cookies:
                    self.cookies = resp.cookies
                print(resp.status_code)
                if resp.status_code == 200:
                    json = resp.json()
                    print(json['state'])
                    if json['state'] == 'DONE GATHERING RESULTS':
                        return json['messageCount']

                raise
            except:
                sleep(1)

    def get_logs(self, job_url, count):
        """
        Iterate through all Sumologic logs for the given job.

        :param str job_url: The job URL.
        :param int count: The number of logs to retrieve.

        :rtype: generator
        :returns: A generator which returns a single JSON log until all logs have
            been retrieved.
        """
        for page in range(0, int(count / self.MESSAGES_PER_PAGE) + 1):
            while True:
                print(f'fetching page {page} of {count/self.MESSAGES_PER_PAGE}')
                try:
                    resp = get(
                        job_url + '/messages',
                        auth = self.credentials,
                        headers = self.SUMOLOGIC_HEADERS,
                        timeout = self.TIMEOUT,
                        params = {
                            'limit': int(self.MESSAGES_PER_PAGE),
                            'offset': int(self.MESSAGES_PER_PAGE * page),
                        },
                        cookies = self.cookies,
                    )
                    if resp.cookies:
                        self.cookies = resp.cookies
                    print(resp.status_code)
                    if resp.status_code == 200:
                        json = resp.json()
                        for log in json['messages']:
                            yield log['map']

                        break

                    raise
                except:
                    print('exception')
                    sleep(1)


def configure():
    """
    Read in and store the user's Sumologic credentials.

    Credentials will be stored in ~/.sumo
    """
    print('Initializing `sumologic-export`...\n')
    print("To get started, we'll need to get your Sumologic credentials.")

    while True:
        access_id = input('Enter your access id: ').strip()
        access_key = input('Enter your access key: ').strip()
        if not (access_id or access_key):
            print('\nYour Sumologic credentials are needed to continue!\n')
            continue

        print('Your API credentials are stored in the file:', CONFIG_FILE, '\n')
        print('Run sumologic-export for usage information.')

        with open(CONFIG_FILE, 'w') as cfg:
            cfg.write(dumps({
                'access_id': access_id,
                'access_key': access_key,
            }, indent=2, sort_keys=True))

        # Make the configuration file only accessible to the current user --
        # this makes the credentials a bit more safe.
        chmod(CONFIG_FILE, 0o600)

        break


def main(args):
    """
    Handle command line options.

    :param args: Command line arguments.
    """
    if args['-v']:
        print(VERSION)
        raise SystemExit()

    elif args['configure']:
        configure()
        raise SystemExit()

    exporter = Exporter()
    exporter.export(args['<start>'], args['<stop>'])


if __name__ == '__main__':
    main(docopt(__doc__, version=VERSION))
